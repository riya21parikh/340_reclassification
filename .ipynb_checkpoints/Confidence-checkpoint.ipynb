{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e964389-ca42-431e-908a-616380202d6b",
   "metadata": {},
   "source": [
    "# This makes sense to use using KMEANS or some other external-based-confidence score, but I didn't realize till I figured out the multiple inputs stuff, gonna leave it but actually work on the confidence-relabeling first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b497b9ed-b6ac-44a6-9aff-456e09a9c144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e95280c4-13b0-45cc-a013-6ca2f30b0ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directories for train and validation sets\n",
    "root_dir = '/projectnb/ds340/projects/Samuolis_Parikh_Image_Data/'\n",
    "\n",
    "train_dir = root_dir +\"resized_images/train\"\n",
    "validation_dir = root_dir + \"resized_images/validation\"\n",
    "\n",
    "train_target = train_dir +\"/baldeagle\"\n",
    "train_nontarget = train_dir +\"/nonbaldeagle\"\n",
    "\n",
    "val_target = validation_dir +\"/baldeagle\"\n",
    "val_nontarget = validation_dir +\"/nonbaldeagle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a74d33b9-6ff2-4aac-a4b7-9576a8d52d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folders(folder1, folder2, img_size = (224,224)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Load images from the first folder\n",
    "    for filename in os.listdir(folder1):\n",
    "        img_path = os.path.join(folder1, filename)\n",
    "        try:\n",
    "            with Image.open(img_path) as img:\n",
    "                img = img.convert('RGB')\n",
    "                img = img.resize(img_size)\n",
    "                images.append(np.array(img))  # Convert image to array\n",
    "                labels.append(1)  # Class label for folder1\n",
    "        except Exception as e:\n",
    "            print(f\"Could not load image {filename} from {folder1}: {e}\")\n",
    "\n",
    "    # Load images from the second folder\n",
    "    for filename in os.listdir(folder2):\n",
    "        img_path = os.path.join(folder2, filename)\n",
    "        try:\n",
    "            with Image.open(img_path) as img:\n",
    "                img = img.convert('RGB')\n",
    "                img = img.resize(img_size)\n",
    "                images.append(np.array(img))\n",
    "                labels.append(0)  # Class label for folder2\n",
    "        except Exception as e:\n",
    "            print(f\"Could not load image {filename} from {folder2}: {e}\")\n",
    "\n",
    "    # convert lists to NumPy arrays\n",
    "    \n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "images_train, label_train = load_images_from_folders(train_target, train_nontarget)\n",
    "images_val, label_val = load_images_from_folders(val_target, val_nontarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2507e8ba-a9a4-4bf5-87dc-64cc4528b293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5200, 224, 224, 3) (5200,) <class 'numpy.ndarray'>\n",
      "0 255\n"
     ]
    }
   ],
   "source": [
    "print(images_train.shape, label_train.shape, type(images_train))\n",
    "print(images_train.min(), images_train.max())  # expected: 0 255, later will normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79236d4d-b08c-4630-a005-0da7c7d0c1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_labels(labels, percentage):\n",
    "    random.seed(340)\n",
    "    label_one_indices = np.where(labels == 1)[0]\n",
    "    \n",
    "    n = int(len(label_one_indices) * (percentage / 100))\n",
    "    \n",
    "    indices_to_change = np.random.choice(label_one_indices, size=n, replace=False)\n",
    "    \n",
    "    labels[indices_to_change] = 0\n",
    "    \n",
    "    return labels, indices_to_change\n",
    "\n",
    "# for example, change 20% of label 1s to label 0\n",
    "percentage = 0  \n",
    "# changed_indices\n",
    "# label_train, changed_indices = change_labels(label_train, percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f8fe98c-89ce-4d1f-a0f3-840d49eebdca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 16:40:33.729987: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-27 16:40:33.751767: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732743633.766199 1251844 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732743633.770394 1251844 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-27 16:40:33.785677: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "tf.keras.utils.set_random_seed(340)\n",
    "tf.config.experimental.enable_op_determinism()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "66d6aebd-c991-4a74-9b33-f1e5920218c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "]\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e3319a3-82bf-42a0-afb7-d005da2bbfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reload Images\n",
    "images_train, label_train = load_images_from_folders(train_target, train_nontarget)\n",
    "percentage = 20  \n",
    "# changed_indices\n",
    "label_train, changed_indices = change_labels(label_train, percentage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64eef54-df72-4075-a370-f590a2f831db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edc6bb0d-c497-4678-b99a-3b09be10c399",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset Generators\n",
    "data_gen_args = {\n",
    "    'rescale': 1.0 / 255.0,  # normalize pixel values\n",
    "}\n",
    "\n",
    "train_datagen = ImageDataGenerator(**data_gen_args)\n",
    "validation_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "# load data with binary labels\n",
    "train_generator = train_datagen.flow(\n",
    "    x = images_train,\n",
    "    y = label_train,\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow(\n",
    "    x = images_val,\n",
    "    y = label_val,\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53324f90-6403-461d-a558-6a45c5e3e4c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bc5ea703-0063-4f68-84fa-da03d64bef30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 16:58:07.820096: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_16}}\n",
      "/projectnb/ds340/students/samuolis/.conda/envs/my_conda_env/lib/python3.10/site-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_175', 'additional_input']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7754 - loss: 6.6949"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 16:58:33.308436: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_16}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 144ms/step - accuracy: 0.7759 - loss: 6.6667 - val_accuracy: 1.0000 - val_loss: 0.0581\n",
      "Epoch 2/15\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 142ms/step - accuracy: 0.9807 - loss: 0.1067 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
      "Epoch 3/15\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 142ms/step - accuracy: 0.9963 - loss: 0.0311 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 4/15\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 142ms/step - accuracy: 0.9984 - loss: 0.0141 - val_accuracy: 1.0000 - val_loss: 8.2334e-04\n",
      "Epoch 5/15\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 142ms/step - accuracy: 0.9985 - loss: 0.0089 - val_accuracy: 1.0000 - val_loss: 6.0229e-04\n",
      "Epoch 6/15\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 4.8740e-04\n",
      "Epoch 7/15\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 3.3004e-04\n",
      "Epoch 8/15\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 142ms/step - accuracy: 0.9998 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 2.5375e-04\n",
      "Epoch 9/15\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 142ms/step - accuracy: 0.9998 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 2.1208e-04\n",
      "Epoch 10/15\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 9.8923e-04 - val_accuracy: 1.0000 - val_loss: 2.2569e-04\n",
      "Epoch 11/15\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 142ms/step - accuracy: 0.9998 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 4.5644e-04\n",
      "Epoch 12/15\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 9.7183e-04 - val_accuracy: 1.0000 - val_loss: 2.8367e-04\n"
     ]
    }
   ],
   "source": [
    "#Remake Models\n",
    "#mutliple inputs taken from chat and https://pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dropout, Concatenate\n",
    "confidence_init = np.array([.5 if x<.5 else 1 for x in label_train]).reshape(5200,1)\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "\n",
    "# add new fully connected layers for binary classification\n",
    "image_input = base_model.input\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "\n",
    "\n",
    "additional_input = Input(shape=(1,), name=\"additional_input\")\n",
    "y = Dense(64, activation='relu')(additional_input)\n",
    "y = Dropout(0.5)(y)\n",
    "\n",
    "combined = Concatenate()([x, y])\n",
    "combined = Dense(256, activation='relu')(combined)\n",
    "combined = Dense(1, activation='sigmoid')(combined)  # sigmoid for binary \n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=[image_input, additional_input], outputs=combined)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'], jit_compile=False)\n",
    "\n",
    "# train model\n",
    "history = model.fit(\n",
    "    [images_train, confidence_init],\n",
    "    label_train,\n",
    "    batch_size = 32,\n",
    "    epochs=epochs,  # adjust this for more epochs as needed\n",
    "    validation_data=([images_val, label_val.reshape(-1,1)], label_val),\n",
    "    callbacks = callbacks\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dc85507c-4510-48e0-995a-d35f93bc8fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/163\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 244ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 17:02:57.865350: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict([images_train, confidence_init])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7c5a0027-b4fa-443a-9957-1b764db26b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    7,   10,   15,   18,   25,   33,   34,   36,   43,   45,\n",
       "         46,   47,   51,   53,   55,   59,   71,   72,   73,   74,   82,\n",
       "         91,   93,   95,  105,  106,  107,  120,  123,  124,  130,  134,\n",
       "        138,  145,  146,  148,  149,  150,  158,  160,  169,  193,  201,\n",
       "        204,  207,  224,  228,  235,  239,  245,  249,  255,  260,  266,\n",
       "        269,  273,  283,  290,  292,  293,  298,  304,  306,  307,  311,\n",
       "        313,  315,  322,  326,  329,  336,  340,  341,  349,  351,  352,\n",
       "        353,  357,  362,  364,  368,  370,  377,  378,  385,  386,  387,\n",
       "        388,  392,  400,  403,  409,  410,  414,  417,  423,  428,  432,\n",
       "        436,  438,  455,  458,  460,  465,  470,  477,  480,  482,  486,\n",
       "        499,  511,  530,  533,  534,  537,  546,  547,  553,  564,  566,\n",
       "        572,  573,  574,  578,  598,  601,  604,  619,  623,  634,  656,\n",
       "        665,  666,  672,  674,  675,  677,  684,  687,  688,  689,  698,\n",
       "        710,  720,  723,  724,  731,  734,  738,  743,  777,  781,  782,\n",
       "        786,  790,  794,  802,  803,  810,  811,  818,  822,  825,  829,\n",
       "        830,  833,  836,  837,  839,  841,  849,  850,  856,  858,  859,\n",
       "        861,  865,  866,  867,  874,  877,  879,  882,  884,  900,  901,\n",
       "        905,  909,  913,  918,  923,  926,  938,  945,  947,  953,  969,\n",
       "        973,  976,  986,  996, 1001, 1007, 1014, 1019, 1029, 1032, 1039,\n",
       "       1041, 1050, 1052, 1055, 1068, 1078, 1082, 1083, 1085, 1086, 1087,\n",
       "       1089, 1096, 1100, 1101, 1103, 1105, 1109, 1140, 1148, 1151, 1157,\n",
       "       1177, 1178, 1179, 1187, 1188, 1193, 1200, 1201, 1203, 1211, 1213,\n",
       "       1216, 1217, 1220, 1221, 1223, 1230, 1232, 1235, 1240, 1244, 1245,\n",
       "       1249, 1263, 1265, 1267, 1268, 1291, 1299])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "changed_indices.sort()\n",
    "changed_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "864f5896-3699-4f29-8b7d-c89288471ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1040,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(label_train > .5)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5bf2c9cc-fad0-49d6-8028-7d95112cb62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1040,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds\n",
    "preds.reshape(5200,)\n",
    "np.where(preds.reshape(5200,) >.5)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ad917216-e690-4251-a548-603ac9d890de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.0006200196)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[changed_indices].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "69af3e9b-4a68-46fd-81ab-e386ba308480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.00046571164)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[1300:].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c095c7-1a2e-4b19-8d92-25bc65f88e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Input, Dropout, Concatenate\n",
    "confidence_init = preds\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "\n",
    "# add new fully connected layers for binary classification\n",
    "image_input = base_model.input\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "\n",
    "\n",
    "additional_input = Input(shape=(1,), name=\"additional_input\")\n",
    "y = Dense(64, activation='relu')(additional_input)\n",
    "y = Dropout(0.5)(y)\n",
    "\n",
    "combined = Concatenate()([x, y])\n",
    "combined = Dense(256, activation='relu')(combined)\n",
    "combined = Dense(1, activation='sigmoid')(combined)  # sigmoid for binary \n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=[image_input, additional_input], outputs=combined)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'], jit_compile=False)\n",
    "\n",
    "# train model\n",
    "history = model.fit(\n",
    "    [images_train, confidence_init],\n",
    "    label_train,\n",
    "    batch_size = 32,\n",
    "    epochs=epochs,  # adjust this for more epochs as needed\n",
    "    validation_data=([images_val, label_val.reshape(-1,1)], label_val),\n",
    "    callbacks = callbacks\n",
    "\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
