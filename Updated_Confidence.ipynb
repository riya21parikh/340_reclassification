{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e964389-ca42-431e-908a-616380202d6b",
   "metadata": {},
   "source": [
    "# This makes sense to use using KMEANS or some other external-based-confidence score, but I didn't realize till I figured out the multiple inputs stuff, gonna leave it but actually work on the confidence-relabeling first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b497b9ed-b6ac-44a6-9aff-456e09a9c144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e95280c4-13b0-45cc-a013-6ca2f30b0ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directories for train and validation sets\n",
    "root_dir = '/projectnb/ds340/projects/Samuolis_Parikh_Image_Data/'\n",
    "\n",
    "train_dir = root_dir +\"resized_images/train\"\n",
    "validation_dir = root_dir + \"resized_images/validation\"\n",
    "\n",
    "train_target = train_dir +\"/baldeagle\"\n",
    "train_nontarget = train_dir +\"/nonbaldeagle\"\n",
    "\n",
    "val_target = validation_dir +\"/baldeagle\"\n",
    "val_nontarget = validation_dir +\"/nonbaldeagle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a74d33b9-6ff2-4aac-a4b7-9576a8d52d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folders(folder1, folder2, img_size = (224,224)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Load images from the first folder\n",
    "    for filename in os.listdir(folder1):\n",
    "        img_path = os.path.join(folder1, filename)\n",
    "        try:\n",
    "            with Image.open(img_path) as img:\n",
    "                img = img.convert('RGB')\n",
    "                img = img.resize(img_size)\n",
    "                images.append(np.array(img))  # Convert image to array\n",
    "                labels.append(1)  # Class label for folder1\n",
    "        except Exception as e:\n",
    "            print(f\"Could not load image {filename} from {folder1}: {e}\")\n",
    "\n",
    "    # Load images from the second folder\n",
    "    for filename in os.listdir(folder2):\n",
    "        img_path = os.path.join(folder2, filename)\n",
    "        try:\n",
    "            with Image.open(img_path) as img:\n",
    "                img = img.convert('RGB')\n",
    "                img = img.resize(img_size)\n",
    "                images.append(np.array(img))\n",
    "                labels.append(0)  # Class label for folder2\n",
    "        except Exception as e:\n",
    "            print(f\"Could not load image {filename} from {folder2}: {e}\")\n",
    "\n",
    "    # convert lists to NumPy arrays\n",
    "    \n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "images_train, label_train = load_images_from_folders(train_target, train_nontarget)\n",
    "images_val, label_val = load_images_from_folders(val_target, val_nontarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2fc677bc-cf4f-4345-9025-45a27bf0a1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5200, 224, 224, 3) (5200,) <class 'numpy.ndarray'>\n",
      "0 255\n",
      "Initial eagle count: 1300\n",
      "Initial noneagle count: 3900\n"
     ]
    }
   ],
   "source": [
    "## for debugging:\n",
    "print(images_train.shape, label_train.shape, type(images_train))\n",
    "print(images_train.min(), images_train.max())  # expected: 0 255, later will normalize\n",
    "print(f\"Initial eagle count: {np.sum(label_train == 1)}\")\n",
    "print(f\"Initial noneagle count: {np.sum(label_train == 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "79236d4d-b08c-4630-a005-0da7c7d0c1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_labels(labels, percentage):\n",
    "    random.seed(340)\n",
    "    label_one_indices = np.where(labels == 1)[0]\n",
    "    \n",
    "    n = int(len(label_one_indices) * (percentage / 100))\n",
    "    \n",
    "    indices_to_change = np.random.choice(label_one_indices, size=n, replace=False)\n",
    "    \n",
    "    labels[indices_to_change] = 0\n",
    "    \n",
    "    return labels, indices_to_change\n",
    "\n",
    "# for example, change 20% of label 1s to label 0\n",
    "percentage = 0  \n",
    "# changed_indices\n",
    "# label_train, changed_indices = change_labels(label_train, percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2f8fe98c-89ce-4d1f-a0f3-840d49eebdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "tf.keras.utils.set_random_seed(340)\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "66d6aebd-c991-4a74-9b33-f1e5920218c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "]\n",
    "epochs = 15\n",
    "# restore best weights make the model be the one that was the best instead of last one\n",
    "# patience changed from 4-->3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6e3319a3-82bf-42a0-afb7-d005da2bbfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload images\n",
    "images_train, label_train = load_images_from_folders(train_target, train_nontarget)\n",
    "percentage = 20  \n",
    "# changed_indices\n",
    "label_train, changed_indices = change_labels(label_train, percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e64eef54-df72-4075-a370-f590a2f831db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New eagle count: 1040\n",
      "New noneagle count: 4160\n"
     ]
    }
   ],
   "source": [
    "print(f\"New eagle count: {np.sum(label_train == 1)}\")\n",
    "print(f\"New noneagle count: {np.sum(label_train == 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "44e5183d-4eb9-40e1-8066-a17ae72e4d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New eagle count: 1040\n",
      "New noneagle count: 4160\n",
      "Confidence values: [0.35 1.   1.   1.   1.   1.   1.   0.35 1.   1.  ]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dropout, Concatenate\n",
    "confidence_init = np.ones_like(label_train, dtype=float)  # Start with all 1s for confidence\n",
    "confidence_init[label_train == 0] = 0  # Set confidence to 0 for original 0 labels\n",
    "confidence_init[changed_indices] = 0.35  # Set confidence to 0.35 for flipped labels\n",
    "confidence_init = confidence_init.reshape(-1, 1)  # Reshape to (N, 1)\n",
    "\n",
    "# print data statistics\n",
    "print(f\"New eagle count: {np.sum(label_train == 1)}\")\n",
    "print(f\"New noneagle count: {np.sum(label_train == 0)}\")\n",
    "print(f\"Confidence values: {confidence_init[:10].flatten()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bc5ea703-0063-4f68-84fa-da03d64bef30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remake models\n",
    "# mutliple inputs taken from chat and https://pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/\n",
    "# we have full confidence if it is a 1, the lower the number the more confident you are in the 0 class\n",
    "# .999999 vs .00004\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "\n",
    "# add new fully connected layers for binary classification\n",
    "image_input = base_model.input\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "\n",
    "additional_input = Input(shape=(1,), name=\"additional_input\") # shape is just 1 feature for the confidence \n",
    "y = Dense(64, activation='relu')(additional_input) \n",
    "y = Dropout(0.1)(y) # when .5, the additional input was too powerful, the prediction vals were always either to close to 1 or 0, we try to make the additional input less important than the images\n",
    "\n",
    "combined = Concatenate()([x, y]) # 2 channels\n",
    "combined = Dense(256, activation='relu')(combined)\n",
    "combined = Dense(1, activation='sigmoid')(combined)  # sigmoid for binary \n",
    "\n",
    "model = Model(inputs=[image_input, additional_input], outputs=combined)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'], jit_compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eb2782-7568-4166-844b-148627328c6c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### didnt run any of this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed71e4b7-0248-443a-9690-dee283ba7c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    [images_train, confidence_init],\n",
    "    label_train,\n",
    "    batch_size = 32,\n",
    "    epochs=epochs,  # adjust this for more epochs as needed\n",
    "    validation_data=([images_val, label_val.reshape(-1,1)], label_val),\n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc85507c-4510-48e0-995a-d35f93bc8fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accracy isnt what we care about rn, we care more about the confidence score and actual classigications\n",
    "preds = model.predict([images_train, confidence_init])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c5a0027-b4fa-443a-9957-1b764db26b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    7,   10,   15,   18,   25,   33,   34,   36,   43,   45,\n",
       "         46,   47,   51,   53,   55,   59,   71,   72,   73,   74,   82,\n",
       "         91,   93,   95,  105,  106,  107,  120,  123,  124,  130,  134,\n",
       "        138,  145,  146,  148,  149,  150,  158,  160,  169,  193,  201,\n",
       "        204,  207,  224,  228,  235,  239,  245,  249,  255,  260,  266,\n",
       "        269,  273,  283,  290,  292,  293,  298,  304,  306,  307,  311,\n",
       "        313,  315,  322,  326,  329,  336,  340,  341,  349,  351,  352,\n",
       "        353,  357,  362,  364,  368,  370,  377,  378,  385,  386,  387,\n",
       "        388,  392,  400,  403,  409,  410,  414,  417,  423,  428,  432,\n",
       "        436,  438,  455,  458,  460,  465,  470,  477,  480,  482,  486,\n",
       "        499,  511,  530,  533,  534,  537,  546,  547,  553,  564,  566,\n",
       "        572,  573,  574,  578,  598,  601,  604,  619,  623,  634,  656,\n",
       "        665,  666,  672,  674,  675,  677,  684,  687,  688,  689,  698,\n",
       "        710,  720,  723,  724,  731,  734,  738,  743,  777,  781,  782,\n",
       "        786,  790,  794,  802,  803,  810,  811,  818,  822,  825,  829,\n",
       "        830,  833,  836,  837,  839,  841,  849,  850,  856,  858,  859,\n",
       "        861,  865,  866,  867,  874,  877,  879,  882,  884,  900,  901,\n",
       "        905,  909,  913,  918,  923,  926,  938,  945,  947,  953,  969,\n",
       "        973,  976,  986,  996, 1001, 1007, 1014, 1019, 1029, 1032, 1039,\n",
       "       1041, 1050, 1052, 1055, 1068, 1078, 1082, 1083, 1085, 1086, 1087,\n",
       "       1089, 1096, 1100, 1101, 1103, 1105, 1109, 1140, 1148, 1151, 1157,\n",
       "       1177, 1178, 1179, 1187, 1188, 1193, 1200, 1201, 1203, 1211, 1213,\n",
       "       1216, 1217, 1220, 1221, 1223, 1230, 1232, 1235, 1240, 1244, 1245,\n",
       "       1249, 1263, 1265, 1267, 1268, 1291, 1299])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "changed_indices.sort()\n",
    "changed_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "864f5896-3699-4f29-8b7d-c89288471ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1040,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(label_train > .5)[0].shape #260 eagles missing, instead more eagles are getting flipped to noneagles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bf2c9cc-fad0-49d6-8028-7d95112cb62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1040,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds\n",
    "preds.reshape(5200,)\n",
    "np.where(preds.reshape(5200,) >.5)[0].shape #find indices of those 17 indexes that were incorrectly flipped and flip them to correct label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad917216-e690-4251-a548-603ac9d890de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007381159"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[changed_indices].mean() #preds for eagles labeled as 0, could we try flipping back top/highest value n percent of these back into eagles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69af3e9b-4a68-46fd-81ab-e386ba308480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002475439"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[1300:].mean() #noneagles labeled as noneagles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25f499be-edde-4e7b-a970-d5a0e7fef88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "tstat, pval = ttest_ind(preds[changed_indices], preds[1300:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ab1ddfe-875c-46dc-ab98-bbe1b6d5dcd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.51675191e-17])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "841452da-aeab-43db-8108-232093a6af0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, \"multi_input_and_output_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79a5a32-3422-4a93-96a1-44112e0e0911",
   "metadata": {},
   "source": [
    "and this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e92ba7-948f-4e38-af46-e400f47c17b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### riya 12/2 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "269dee85-444c-41fb-956d-89713c2d7bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1...\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step\n",
      "Changed Indices: [  15   25   55   73  201  235  283  315  353  368  378  410  417  428\n",
      "  432  438  455  465  530  547  578  674  684  724  802  803  829  836\n",
      "  837  849  856  861  918  973 1029 1052 1085 1086 1101 1177 1193 1211\n",
      " 1213 1221 1299]\n",
      "Predictions for Changed Indices: [0.33993948 0.301688   0.31609848 0.346323   0.31062728 0.3332955\n",
      " 0.31176782 0.31758687 0.33170742 0.30259776 0.3220533  0.3301907\n",
      " 0.3241291  0.34405994 0.31074417 0.30899304 0.31454054 0.30906466\n",
      " 0.36607313 0.30413967 0.39055392 0.31689996 0.3912428  0.34620482\n",
      " 0.30776814 0.32108304 0.30376634 0.3192135  0.30213514 0.30695465\n",
      " 0.49647298 0.3226291  0.37533212 0.31266627 0.31192333 0.3216466\n",
      " 0.36463854 0.31626424 0.35049868 0.32555488 0.37126392 0.30479458\n",
      " 0.31322291 0.31673646 0.36950284]\n",
      "Label change ratio: 0.0000\n",
      "Eagles in predictions: 1040\n",
      "Noneagles in predictions: 4160\n",
      "Labels have converged.\n",
      "After Convergence - Correctly labeled eagles: 1040\n",
      "After Convergence - Correctly labeled noneagles: 4160\n"
     ]
    }
   ],
   "source": [
    "#trash rn\n",
    "import numpy as np\n",
    "\n",
    "# Define function to update labels based on misclassifications and confidence\n",
    "def update_labels(preds, labels, changed_indices, confidence_init, threshold=0.05):\n",
    "    new_labels = labels.copy()\n",
    "\n",
    "    # Misclassified eagles: predicted as non-eagles (preds <= 0.5) but they are actually eagles (labels == 1)\n",
    "    misclassified_eagles = np.where((labels[:1300] == 1) & (preds[:1300] <= 0.5))[0]\n",
    "\n",
    "    # Adjust confidence for misclassifications within the eagle class\n",
    "    for idx in misclassified_eagles:\n",
    "        confidence_init[idx] = min(confidence_init[idx] + 0.1, 1)  # Increase confidence for eagle class\n",
    "\n",
    "    # Flip misclassified eagles to eagles (preds closer to 1) if confidently predicted\n",
    "    for idx in misclassified_eagles:\n",
    "        new_labels[idx] = 1  # Flip to eagle\n",
    "\n",
    "    return new_labels  \n",
    "\n",
    "# Iterative relabeling process\n",
    "converged = False\n",
    "iteration = 0\n",
    "threshold = 0.05  # Statistical significance level\n",
    "tolerance = 0.01  # Convergence tolerance (less than 1% labels change)\n",
    "\n",
    "\n",
    "# Start iterative process\n",
    "while not converged:\n",
    "    iteration += 1\n",
    "    print(f\"Iteration {iteration}...\")\n",
    "\n",
    "    # Retrain the model with the current labels and confidence scores\n",
    "    history = model.fit(\n",
    "        [images_train, confidence_init],  # Use updated confidence\n",
    "        label_train,\n",
    "        batch_size=32,\n",
    "        epochs=1,  # To see values after each iteration\n",
    "        validation_data=([images_val, label_val.reshape(-1, 1)], label_val),\n",
    "        callbacks=callbacks,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Predict updated confidence scores from the model\n",
    "    preds = model.predict([images_train, confidence_init]).flatten()\n",
    "\n",
    "    # Filter `changed_indices` to keep only ambiguous predictions\n",
    "    changed_indices = changed_indices[np.where((preds[changed_indices] > 0.3) & (preds[changed_indices] < 0.7))[0]]\n",
    "    changed_indices = np.sort(changed_indices)\n",
    "\n",
    "    print(f\"Changed Indices: {changed_indices}\")\n",
    "    print(f\"Predictions for Changed Indices: {preds[changed_indices]}\")\n",
    "\n",
    "    # Update labels based on misclassifications and confidence\n",
    "    new_labels = update_labels(preds, label_train, changed_indices, confidence_init, threshold)\n",
    "\n",
    "    # Update confidence scores to reflect updated predictions\n",
    "    confidence_init = preds.reshape(-1, 1)\n",
    "\n",
    "    # Check for convergence\n",
    "    label_changes = np.sum(label_train != new_labels)\n",
    "    change_ratio = label_changes / len(label_train)\n",
    "    print(f\"Label change ratio: {change_ratio:.4f}\")\n",
    "    print(f\"Eagles in predictions: {np.sum(preds > 0.5)}\")\n",
    "    print(f\"Noneagles in predictions: {np.sum(preds <= 0.5)}\")\n",
    "\n",
    "    # Check if the labels have converged by comparing the old and new labels\n",
    "    if change_ratio < tolerance:  \n",
    "        converged = True\n",
    "    else:\n",
    "        label_train = new_labels.copy()  # Update labels for the next iteration\n",
    "\n",
    "print(\"Labels have converged.\")\n",
    "\n",
    "# Final print\n",
    "eagle_count = np.sum(label_train == 1)\n",
    "noneagle_count = np.sum(label_train == 0)\n",
    "print(f\"After Convergence - Correctly labeled eagles: {eagle_count}\")\n",
    "print(f\"After Convergence - Correctly labeled noneagles: {noneagle_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba674e1-757a-4db3-b351-f36bc3c645a7",
   "metadata": {},
   "source": [
    "### riya 12/2 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "74453bdf-a5c0-4764-b238-901b1f3a8810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1...\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step\n",
      "Adjusted 208 indices, avg confidence: 0.0011\n",
      "Changed Indices: [ 634 1050  370   34  986  149  499  720 1032  260  432  601  867  130\n",
      " 1052  564  688  619  781  675  918 1178 1223  782  731  856  362  969\n",
      "  578  861   72   71  743  283  837  313  882  134  938  822   10  311\n",
      "  953   25  148  438  666  850  546  874 1240  849  378  377  249 1014\n",
      "  160 1151  923   59  460  138 1187  573   15  470  723  794  106 1140\n",
      " 1041  905  511  201  204  777  803  574 1211 1082 1249 1087  245  107\n",
      "  533  307  341  604 1291 1105  410  207  877  913   53 1299 1265   55\n",
      "  537 1203  292  547   47  351  818  790  865 1078  255  458 1101  235\n",
      "  105  326  973  684   91 1263 1085   95  290    7 1029  945  926 1232\n",
      "  672  859 1244  534  879  388  123  120 1100  909    0  266  455 1179\n",
      "  553  269  322  304  298  724  884 1217  387 1268  598   74  677  530\n",
      "   45  572 1213 1086 1103 1109  738   82  839  385  400  349 1177  900\n",
      "  357  810   93 1235 1216  665   73  947  224 1200  386   46 1201   51\n",
      "  901  465  239  414  786  329  392 1039 1007  734  352  482   18 1193\n",
      "   43  417  477  428  364  689 1083  423 1157  409  841  976 1267  480\n",
      "  829  833  623  830  336 1001 1089  486 1055  687  306  124  866  145\n",
      "  169  858  802  315  368  403  656 1188 1148 1019  698  674  293  566\n",
      " 1068   36  158  436  996 1230  340  150   33  710  836  146 1245 1221\n",
      "  353  273 1096  228  811  825  193 1220]\n",
      "Predictions for Changed Indices: [0.14698198 0.08105592 0.09259105 0.07273275 0.08966894 0.08374815\n",
      " 0.0720187  0.07050358 0.06241228 0.08375508 0.07039426 0.10454656\n",
      " 0.08180402 0.0891483  0.11123827 0.03073414 0.13788709 0.15575719\n",
      " 0.0865363  0.06309564 0.08788458 0.08589068 0.06583675 0.08671241\n",
      " 0.07360455 0.12211581 0.09069543 0.10823644 0.00035119 0.09746071\n",
      " 0.07839868 0.07695532 0.13538758 0.07743233 0.09149564 0.09901578\n",
      " 0.06980311 0.10387171 0.09478067 0.08680868 0.06514769 0.08000872\n",
      " 0.06128809 0.06988596 0.07322241 0.09363873 0.03568991 0.09660935\n",
      " 0.13546497 0.07978414 0.08909078 0.08003435 0.06738131 0.0855047\n",
      " 0.05548643 0.11489457 0.08193008 0.09491501 0.09102888 0.10367376\n",
      " 0.09732651 0.0500621  0.06633259 0.0872179  0.07917348 0.09289615\n",
      " 0.09452836 0.08315962 0.07715098 0.08730621 0.10063355 0.08753675\n",
      " 0.07855917 0.079211   0.07782935 0.0733292  0.05461534 0.09709213\n",
      " 0.10410102 0.09205621 0.08619759 0.0790659  0.08376308 0.09534004\n",
      " 0.01566844 0.10794919 0.09239189 0.13686793 0.0868393  0.06205774\n",
      " 0.12135815 0.07890169 0.07433493 0.0775772  0.08135428 0.09047446\n",
      " 0.09654742 0.07131316 0.14517422 0.09421872 0.09845343 0.11263014\n",
      " 0.09504988 0.05099086 0.07800651 0.07852901 0.07219383 0.11511034\n",
      " 0.0974119  0.09929231 0.07278806 0.12824102 0.0843145  0.08328965\n",
      " 0.07925802 0.05103315 0.01640309 0.08760951 0.07735763 0.10235651\n",
      " 0.08484045 0.0869631  0.16394025 0.04946623 0.08583213 0.07690836\n",
      " 0.08462713 0.06758997 0.08457975 0.10492007 0.04625582 0.1568413\n",
      " 0.08819027 0.08258909 0.080828   0.08438876 0.07827818 0.07375239\n",
      " 0.09386478 0.08772538 0.06780828 0.0852488  0.07992796 0.16691169\n",
      " 0.0696164  0.10504397 0.1002646  0.06867334 0.07770205 0.06675172\n",
      " 0.09570219 0.08024246 0.07134984 0.184124   0.1344461  0.10738689\n",
      " 0.10953755 0.10927869 0.09375254 0.02605151 0.08096443 0.08302958\n",
      " 0.07284459 0.08014364 0.10391792 0.10224252 0.10151755 0.0901126\n",
      " 0.08713157 0.07059097 0.07324833 0.08045956 0.08713765 0.06741323\n",
      " 0.0992303  0.06919063 0.0835681  0.07931741 0.07915725 0.10429922\n",
      " 0.07629011 0.08184368 0.07006227 0.12746912 0.088645   0.09948435\n",
      " 0.0756382  0.04648099 0.09209944 0.07108856 0.09468189 0.07607614\n",
      " 0.10368015 0.09505641 0.08496419 0.11487344 0.08713596 0.07398665\n",
      " 0.08470229 0.1087404  0.11082686 0.10123174 0.09833673 0.07980773\n",
      " 0.08280089 0.08003376 0.06903819 0.08224963 0.10829031 0.14447258\n",
      " 0.07434046 0.13211463 0.07614212 0.08878831 0.08478654 0.08987294\n",
      " 0.08987895 0.0842494  0.11134418 0.08599383 0.03642419 0.0803525\n",
      " 0.07127474 0.07285306 0.09723657 0.06960321 0.07716253 0.0807943\n",
      " 0.08713397 0.14963259 0.08910348 0.11478722 0.05367854 0.0661075\n",
      " 0.09182828 0.09152083 0.10029244 0.08935082 0.09360445 0.08471981\n",
      " 0.05721691 0.09077121 0.10538282 0.08471932 0.08313803 0.09448771\n",
      " 0.11560477 0.08653174 0.08384421 0.08424652 0.08674122 0.0729678\n",
      " 0.1083978  0.11809121 0.09840963 0.10954607 0.0754393  0.12508568\n",
      " 0.08136381 0.08381234]\n",
      "Change ratio: 0.0400\n",
      "Iteration 2...\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step\n",
      "Adjusted 208 indices, avg confidence: 0.0002\n",
      "Changed Indices: [ 634 1050  370   34  986  149  499  720 1032  260  432  601  867  130\n",
      " 1052  564  688  619  781  675  918 1178 1223  782  731  856  362  969\n",
      "  578  861   72   71  743  283  837  313  882  134  938  822   10  311\n",
      "  953   25  148  438  666  850  546  874 1240  849  378  377  249 1014\n",
      "  160 1151  923   59  460  138 1187  573   15  470  723  794  106 1140\n",
      " 1041  905  511  201  204  777  803  574 1211 1082 1249 1087  245  107\n",
      "  533  307  341  604 1291 1105  410  207  877  913   53 1299 1265   55\n",
      "  537 1203  292  547   47  351  818  790  865 1078  255  458 1101  235\n",
      "  105  326  973  684   91 1263 1085   95  290    7 1029  945  926 1232\n",
      "  672  859 1244  534  879  388  123  120 1100  909    0  266  455 1179\n",
      "  553  269  322  304  298  724  884 1217  387 1268  598   74  677  530\n",
      "   45  572 1213 1086 1103 1109  738   82  839  385  400  349 1177  900\n",
      "  357  810   93 1235 1216  665   73  947  224 1200  386   46 1201   51\n",
      "  901  465  239  414  786  329  392 1039 1007  734  352  482   18 1193\n",
      "   43  417  477  428  364  689 1083  423 1157  409  841  976 1267  480\n",
      "  829  833  623  830  336 1001 1089  486 1055  687  306  124  866  145\n",
      "  169  858  802  315  368  403  656 1188 1148 1019  698  674  293  566\n",
      " 1068   36  158  436  996 1230  340  150   33  710  836  146 1245 1221\n",
      "  353  273 1096  228  811  825  193 1220]\n",
      "Predictions for Changed Indices: [3.2853324e-02 3.0884322e-02 2.9118149e-02 2.9785866e-02 2.6270300e-02\n",
      " 3.3591975e-02 2.9229913e-02 3.1872328e-02 3.0217638e-02 3.0942764e-02\n",
      " 2.8973017e-02 2.5490806e-02 3.0721186e-02 3.0956540e-02 3.2042939e-02\n",
      " 1.9051639e-02 3.8061872e-02 4.0590018e-02 3.4140915e-02 3.1721078e-02\n",
      " 2.4826607e-02 3.0030262e-02 3.2836270e-02 2.9857267e-02 2.9554732e-02\n",
      " 2.8795240e-02 3.3529554e-02 3.7052467e-02 5.7258530e-05 3.1105217e-02\n",
      " 3.1191722e-02 3.1337909e-02 2.5211617e-02 2.8035514e-02 3.3247728e-02\n",
      " 2.8214391e-02 2.7253054e-02 3.6430970e-02 3.2299288e-02 2.9987833e-02\n",
      " 3.0002078e-02 3.3857033e-02 2.3751322e-02 2.5028842e-02 3.0485706e-02\n",
      " 3.2717373e-02 1.5848573e-02 3.4196433e-02 3.3725910e-02 3.2772288e-02\n",
      " 2.9494036e-02 2.9316200e-02 3.0479847e-02 2.4926858e-02 2.5387919e-02\n",
      " 2.7432963e-02 3.2155488e-02 2.9119816e-02 3.2519199e-02 3.2623842e-02\n",
      " 2.5097290e-02 2.6580874e-02 2.4784667e-02 3.3851076e-02 2.9185973e-02\n",
      " 3.1154590e-02 3.0876888e-02 2.9135175e-02 3.3029415e-02 3.2475587e-02\n",
      " 3.2291014e-02 3.0563846e-02 3.2554157e-02 2.7951440e-02 2.5793260e-02\n",
      " 2.8587388e-02 2.3043215e-02 3.4128450e-02 2.7002787e-02 3.2378651e-02\n",
      " 3.1656139e-02 3.1722374e-02 2.1256227e-02 3.2957859e-02 1.1871437e-02\n",
      " 3.6700591e-02 2.9507805e-02 3.1463243e-02 2.8723948e-02 1.7829647e-02\n",
      " 3.7523631e-02 3.0352551e-02 3.2626998e-02 2.8367361e-02 3.0867008e-02\n",
      " 2.9163396e-02 2.9721478e-02 2.6063930e-02 2.6789274e-02 3.2528818e-02\n",
      " 3.2065332e-02 3.4741566e-02 2.9595824e-02 2.3452373e-02 3.1873293e-02\n",
      " 3.0222258e-02 2.8118102e-02 3.7373960e-02 3.1151472e-02 3.3763044e-02\n",
      " 1.1081771e-02 3.3557687e-02 3.2805875e-02 3.0003674e-02 2.6648099e-02\n",
      " 2.1328066e-02 1.4122785e-02 3.2150902e-02 2.8478667e-02 2.2902241e-02\n",
      " 3.0655470e-02 2.2469727e-02 3.5768073e-02 2.2632428e-02 2.9593885e-02\n",
      " 3.0989515e-02 2.9924121e-02 3.0356102e-02 3.0435627e-02 3.0816860e-02\n",
      " 2.4834784e-02 3.5754375e-02 2.8606096e-02 3.1261861e-02 3.1294465e-02\n",
      " 3.2149106e-02 3.1156078e-02 3.0120077e-02 2.9772358e-02 3.2427453e-02\n",
      " 2.7910359e-02 3.2133412e-02 2.8055441e-02 4.0688254e-02 3.2030296e-02\n",
      " 2.8744083e-02 3.0535035e-02 1.6368611e-02 2.9539995e-02 3.3332851e-02\n",
      " 2.7465653e-02 3.2887846e-02 2.9249419e-02 4.0698782e-02 3.4062933e-02\n",
      " 3.0939016e-02 3.2633256e-02 3.1790044e-02 3.3944830e-02 1.4502898e-02\n",
      " 2.4515701e-02 3.0477196e-02 2.8244480e-02 3.2475781e-02 3.2835033e-02\n",
      " 3.4489270e-02 3.3014845e-02 3.3883732e-02 2.9981991e-02 2.3346469e-02\n",
      " 2.9975474e-02 3.1707570e-02 3.4690868e-02 3.0796280e-02 2.9107172e-02\n",
      " 2.0131465e-02 3.2857101e-02 3.3184581e-02 3.0286295e-02 3.3899482e-02\n",
      " 2.9082892e-02 3.2952562e-02 2.9726068e-02 2.9639773e-02 2.9620985e-02\n",
      " 1.9876840e-02 2.2975856e-02 2.3250820e-02 3.1806335e-02 3.0936228e-02\n",
      " 2.8128065e-02 3.1788275e-02 3.3150651e-02 2.8469268e-02 3.4808107e-02\n",
      " 2.9511143e-02 3.1983115e-02 3.0695459e-02 3.2641042e-02 3.2665908e-02\n",
      " 2.9127065e-02 2.9948283e-02 3.1574555e-02 3.1923611e-02 3.1398136e-02\n",
      " 3.1087946e-02 2.9185446e-02 3.3265412e-02 3.2968141e-02 3.4621492e-02\n",
      " 1.5818749e-02 3.5882108e-02 2.7853334e-02 2.7137104e-02 2.8453963e-02\n",
      " 3.0293051e-02 2.6778752e-02 3.0532638e-02 3.3891216e-02 3.1599872e-02\n",
      " 1.1064822e-02 3.3334766e-02 2.6843678e-02 3.1179409e-02 3.2352220e-02\n",
      " 2.8777035e-02 2.7969569e-02 2.8923353e-02 3.0628933e-02 3.6117885e-02\n",
      " 3.2762162e-02 2.1068024e-02 9.7070094e-03 2.8155211e-02 3.1192023e-02\n",
      " 2.8145470e-02 3.6265634e-02 2.6770039e-02 2.8019719e-02 3.2386474e-02\n",
      " 2.7609484e-02 3.3331163e-02 3.0846382e-02 3.4125920e-02 3.1738482e-02\n",
      " 3.2709345e-02 3.4167044e-02 2.9041169e-02 2.9878585e-02 2.9999753e-02\n",
      " 1.4763724e-02 1.6744288e-02 3.2132477e-02 3.6886960e-02 3.2378525e-02\n",
      " 3.5727926e-02 2.9105144e-02 3.4376249e-02 2.2974925e-02 3.1870667e-02]\n",
      "Change ratio: 0.0400\n",
      "Iteration 3...\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step\n",
      "Adjusted 208 indices, avg confidence: 0.0000\n",
      "Changed Indices: [ 634 1050  370   34  986  149  499  720 1032  260  432  601  867  130\n",
      " 1052  564  688  619  781  675  918 1178 1223  782  731  856  362  969\n",
      "  578  861   72   71  743  283  837  313  882  134  938  822   10  311\n",
      "  953   25  148  438  666  850  546  874 1240  849  378  377  249 1014\n",
      "  160 1151  923   59  460  138 1187  573   15  470  723  794  106 1140\n",
      " 1041  905  511  201  204  777  803  574 1211 1082 1249 1087  245  107\n",
      "  533  307  341  604 1291 1105  410  207  877  913   53 1299 1265   55\n",
      "  537 1203  292  547   47  351  818  790  865 1078  255  458 1101  235\n",
      "  105  326  973  684   91 1263 1085   95  290    7 1029  945  926 1232\n",
      "  672  859 1244  534  879  388  123  120 1100  909    0  266  455 1179\n",
      "  553  269  322  304  298  724  884 1217  387 1268  598   74  677  530\n",
      "   45  572 1213 1086 1103 1109  738   82  839  385  400  349 1177  900\n",
      "  357  810   93 1235 1216  665   73  947  224 1200  386   46 1201   51\n",
      "  901  465  239  414  786  329  392 1039 1007  734  352  482   18 1193\n",
      "   43  417  477  428  364  689 1083  423 1157  409  841  976 1267  480\n",
      "  829  833  623  830  336 1001 1089  486 1055  687  306  124  866  145\n",
      "  169  858  802  315  368  403  656 1188 1148 1019  698  674  293  566\n",
      " 1068   36  158  436  996 1230  340  150   33  710  836  146 1245 1221\n",
      "  353  273 1096  228  811  825  193 1220]\n",
      "Predictions for Changed Indices: [1.21537810e-02 1.41166914e-02 1.18599031e-02 1.21395281e-02\n",
      " 9.71059967e-03 1.32895662e-02 1.23075666e-02 1.37494709e-02\n",
      " 1.34411287e-02 1.19703608e-02 1.31767737e-02 1.11051183e-02\n",
      " 1.23010110e-02 1.23815155e-02 1.16645927e-02 6.68096729e-03\n",
      " 1.58531405e-02 1.50990989e-02 1.39875375e-02 1.48886861e-02\n",
      " 8.24682787e-03 1.18935686e-02 1.37803014e-02 1.16670672e-02\n",
      " 1.11132795e-02 1.37231452e-02 1.43471071e-02 1.49318790e-02\n",
      " 3.19391870e-06 1.23511748e-02 1.29720401e-02 1.28174918e-02\n",
      " 1.02233365e-02 9.76744853e-03 8.92905518e-03 1.09659312e-02\n",
      " 1.09873312e-02 1.41836097e-02 1.21265836e-02 1.18051963e-02\n",
      " 1.32594742e-02 1.36910938e-02 9.40319058e-03 9.29720607e-03\n",
      " 1.32729067e-02 1.33171817e-02 4.39026626e-03 1.34700816e-02\n",
      " 1.18717998e-02 1.33496197e-02 1.14221983e-02 1.14282137e-02\n",
      " 9.66684241e-03 1.00657633e-02 1.01838429e-02 1.12355938e-02\n",
      " 1.33127961e-02 1.15300138e-02 1.30883828e-02 1.32354638e-02\n",
      " 1.06110005e-02 1.19596273e-02 8.66498891e-03 1.28514739e-02\n",
      " 7.94007815e-03 1.17977560e-02 1.32821770e-02 1.11999931e-02\n",
      " 1.48598375e-02 1.31906755e-02 1.42490584e-02 1.14646889e-02\n",
      " 1.37171578e-02 1.04068946e-02 1.11477440e-02 1.26494858e-02\n",
      " 6.22956734e-03 1.37152737e-02 9.66361538e-03 1.31945862e-02\n",
      " 1.14786727e-02 1.40997460e-02 1.10666528e-02 1.34819355e-02\n",
      " 3.96280456e-03 1.51546653e-02 1.15640834e-02 1.42238894e-02\n",
      " 1.13955187e-02 9.84531920e-03 1.67908501e-02 1.20952912e-02\n",
      " 1.43923918e-02 1.13619175e-02 1.23206032e-02 1.19902734e-02\n",
      " 1.04850782e-02 9.69326403e-03 9.87799931e-03 1.25909522e-02\n",
      " 1.33995805e-02 1.37031786e-02 1.15083000e-02 9.71231516e-03\n",
      " 1.32886907e-02 1.20372716e-02 1.11292098e-02 1.49963172e-02\n",
      " 1.21886376e-02 1.36617050e-02 5.53916069e-03 1.26522910e-02\n",
      " 1.35473255e-02 1.20224692e-02 1.04551995e-02 7.42571522e-03\n",
      " 4.29860409e-03 1.28662596e-02 1.14444848e-02 9.96246375e-03\n",
      " 1.20468251e-02 9.39737447e-03 1.22308610e-02 9.24291089e-03\n",
      " 1.20821819e-02 1.30077200e-02 1.22963199e-02 1.36305196e-02\n",
      " 1.19690401e-02 1.00016845e-02 1.14758480e-02 1.15004107e-02\n",
      " 1.24231363e-02 1.22032175e-02 1.20866960e-02 1.36113251e-02\n",
      " 1.27827907e-02 1.25589278e-02 1.11557841e-02 1.48213971e-02\n",
      " 1.19369971e-02 1.33502409e-02 1.08430870e-02 1.47032328e-02\n",
      " 1.56451687e-02 1.12583423e-02 1.17194671e-02 8.59549176e-03\n",
      " 1.21162944e-02 1.49935577e-02 9.30360239e-03 1.38748335e-02\n",
      " 1.22757144e-02 1.32166455e-02 1.26701389e-02 1.19841062e-02\n",
      " 1.26365274e-02 1.07451482e-02 1.47559782e-02 5.39854635e-03\n",
      " 1.06059909e-02 1.27758970e-02 1.14259198e-02 1.36024291e-02\n",
      " 1.33267092e-02 1.53072821e-02 1.34950578e-02 1.39531847e-02\n",
      " 1.20509453e-02 1.13238012e-02 1.28271412e-02 1.35989105e-02\n",
      " 1.53260594e-02 1.30717009e-02 1.12414975e-02 1.07177310e-02\n",
      " 1.41135603e-02 1.50077399e-02 1.24640130e-02 1.40506085e-02\n",
      " 1.31953489e-02 1.39706386e-02 1.29044643e-02 9.70766507e-03\n",
      " 1.14507861e-02 7.49147590e-03 8.53656977e-03 8.42345413e-03\n",
      " 1.12588042e-02 1.32115651e-02 1.08069982e-02 1.40152453e-02\n",
      " 1.32735064e-02 1.04813194e-02 1.44373048e-02 1.04347356e-02\n",
      " 1.26000615e-02 1.30676180e-02 1.28499428e-02 1.22499894e-02\n",
      " 1.24735590e-02 1.17039755e-02 1.30548198e-02 1.32398671e-02\n",
      " 1.28811793e-02 1.28291398e-02 1.21555552e-02 1.43343825e-02\n",
      " 1.25626707e-02 1.32556995e-02 7.13505968e-03 1.47953508e-02\n",
      " 1.10657560e-02 1.05808871e-02 1.13743031e-02 1.10390186e-02\n",
      " 9.67551954e-03 1.18136210e-02 1.39201256e-02 1.24167670e-02\n",
      " 8.30258802e-03 1.43370489e-02 1.07242959e-02 1.35218604e-02\n",
      " 1.20433532e-02 1.15418993e-02 1.01030255e-02 1.19309416e-02\n",
      " 1.19242156e-02 1.32298609e-02 1.35175604e-02 9.55322105e-03\n",
      " 5.43786958e-03 1.24296313e-02 1.12620639e-02 1.06925927e-02\n",
      " 1.51992310e-02 1.08280508e-02 1.05856061e-02 1.43066524e-02\n",
      " 1.14956852e-02 1.23462314e-02 1.23062395e-02 1.49806608e-02\n",
      " 1.27437543e-02 1.30388197e-02 1.34093855e-02 1.17127914e-02\n",
      " 1.25546530e-02 1.15115400e-02 6.59081759e-03 7.97414314e-03\n",
      " 1.20119723e-02 1.52366534e-02 1.18621662e-02 1.46961343e-02\n",
      " 1.20558748e-02 1.27024846e-02 1.02012325e-02 1.27352439e-02]\n",
      "Change ratio: 0.0400\n",
      "Final eagle count: 1040\n",
      "Final noneagle count: 4160\n"
     ]
    }
   ],
   "source": [
    "n_percentage = 5  # % of least confident eagle predictions to adjust\n",
    "max_iterations = 3 # has biggest numbers from above output  \n",
    "convergence_tolerance = 0  # stop if change ratio is this\n",
    "high_conf_threshold = 0.8  # threshold for confident eagle flips\n",
    "\n",
    "for iteration in range(max_iterations):\n",
    "    print(f\"Iteration {iteration + 1}...\")\n",
    "\n",
    "    # step 1: train model\n",
    "    history = model.fit(\n",
    "        [images_train, confidence_init],\n",
    "        label_train,\n",
    "        batch_size=100, # ok this might seem crazy but im wondering if w batch=32 it wasn't encountering enough wrong labels \n",
    "        epochs=1,\n",
    "        # validation_data=([images_val, np.ones((len(images_val), 1))], label_val), # this was a line from chat, replaced w ours instead below\n",
    "        validation_data=([images_val, label_val.reshape(-1,1)], label_val),\n",
    "        callbacks=callbacks,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # step 2: predict probabilities\n",
    "    preds = model.predict([images_train, confidence_init]).flatten()\n",
    "\n",
    "    # step 3: identify least confident eagle predictions\n",
    "    low_confidence_indices = np.where((label_train == 0) & (preds < 0.5) & (preds != 0))[0] # grabbing indices where label_train is 0 (noneagle), focusing in on the misclassified\n",
    "    sorted_indices = low_confidence_indices[np.argsort(preds[low_confidence_indices])] # sorts the preds low to high\n",
    "    to_adjust = sorted_indices[:int(len(sorted_indices) * (n_percentage / 100))] # only grabbing 5% rn of the bottom\n",
    "\n",
    "    # step 4: update confidence for least confident predictions\n",
    "    if len(to_adjust) > 0:\n",
    "        confidence_init[to_adjust] = 0  # reduce confidence to 0 for the indices we picked by %\n",
    "        avg_confidence = np.mean(preds[to_adjust])\n",
    "        print(f\"Adjusted {len(to_adjust)} indices, avg confidence: {avg_confidence:.4f}\")\n",
    "    else:\n",
    "        print(\"No indices to adjust in this iteration.\")\n",
    "    print(f\"Changed Indices: {changed_indices}\")\n",
    "    print(f\"Predictions for Changed Indices: {preds[changed_indices]}\")\n",
    "\n",
    "\n",
    "    # step 5: check for convergence\n",
    "    if len(to_adjust) > 0:\n",
    "            change_ratio = len(to_adjust) / len(label_train)  \n",
    "    else:\n",
    "            change_ratio=0\n",
    "    print(f\"Change ratio: {change_ratio:.4f}\")\n",
    "\n",
    "    if change_ratio < convergence_tolerance:\n",
    "        print(\"Convergence reached.\")\n",
    "        break\n",
    "\n",
    "# step 6: final flipping of high-confidence predictions to eagles\n",
    "high_confidence_indices = np.where((label_train == 0) & (preds > .5))[0]\n",
    "for idx in high_confidence_indices:\n",
    "    label_train[idx] = 1  # flip to eagle\n",
    "    confidence_init[idx] = 1  # restore confidence to 1 for flipped labels\n",
    "\n",
    "print(f\"Final eagle count: {np.sum(label_train == 1)}\")\n",
    "print(f\"Final noneagle count: {np.sum(label_train == 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2f91b3fe-60a7-41e5-b00a-1b19fc9bdfd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1...\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step\n",
      "Adjusted 208 indices, avg confidence: 0.0170\n",
      "Change ratio: 0.0400\n",
      "Iteration 2...\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step\n",
      "Adjusted 208 indices, avg confidence: 0.0012\n",
      "Change ratio: 0.0400\n",
      "Iteration 3...\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step\n",
      "Adjusted 208 indices, avg confidence: 0.0001\n",
      "Change ratio: 0.0400\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step\n",
      "Retraining model with updated labels...\n",
      "Epoch 1/3\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 140ms/step - accuracy: 0.0000e+00 - loss: 0.0130 - val_accuracy: 0.2500 - val_loss: 4.2549\n",
      "Epoch 2/3\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 139ms/step - accuracy: 0.0000e+00 - loss: 0.0127 - val_accuracy: 0.2500 - val_loss: 4.1080\n",
      "Epoch 3/3\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 139ms/step - accuracy: 0.0000e+00 - loss: 0.0127 - val_accuracy: 0.2500 - val_loss: 4.2142\n",
      "Final eagle count: 1040\n",
      "Final noneagle count: 4160\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(max_iterations):\n",
    "    print(f\"Iteration {iteration + 1}...\")\n",
    "\n",
    "    # Step 1: Train model\n",
    "    history = model.fit(\n",
    "        [images_train, confidence_init],\n",
    "        label_train,\n",
    "        batch_size=32,\n",
    "        epochs=1,\n",
    "        validation_data=([images_val, np.ones((len(images_val), 1))], label_val),\n",
    "        callbacks=callbacks,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Step 2: Predict probabilities\n",
    "    preds = model.predict([images_train, confidence_init]).flatten()\n",
    "\n",
    "    # Step 3: Identify least confident predictions\n",
    "    low_confidence_indices = np.where((label_train == 0) & (preds < 0.5) & (preds != 0))[0]\n",
    "    sorted_indices = low_confidence_indices[np.argsort(preds[low_confidence_indices])]\n",
    "    to_adjust = sorted_indices[:int(len(sorted_indices) * (n_percentage / 100))]\n",
    "\n",
    "    # Step 4: Update confidence for least confident predictions\n",
    "    if len(to_adjust) > 0:\n",
    "        confidence_init[to_adjust] *= 0.5  # Reduce confidence gradually\n",
    "        avg_confidence = np.mean(preds[to_adjust])\n",
    "        print(f\"Adjusted {len(to_adjust)} indices, avg confidence: {avg_confidence:.4f}\")\n",
    "    else:\n",
    "        print(\"No indices to adjust in this iteration.\")\n",
    "\n",
    "    # Step 5: Check for convergence\n",
    "    change_ratio = len(to_adjust) / len(label_train) if len(to_adjust) > 0 else 0\n",
    "    print(f\"Change ratio: {change_ratio:.4f}\")\n",
    "    if change_ratio < convergence_tolerance:\n",
    "        print(\"Convergence reached.\")\n",
    "        break\n",
    "\n",
    "# Step 6: Final flipping of high-confidence predictions to eagles\n",
    "preds = model.predict([images_train, confidence_init]).flatten()\n",
    "high_confidence_indices = np.where((label_train == 0) & (preds > high_conf_threshold))[0]\n",
    "\n",
    "if len(high_confidence_indices) > 0:\n",
    "    label_train[high_confidence_indices] = 1\n",
    "    confidence_init[high_confidence_indices] = 1\n",
    "    print(f\"Flipped {len(high_confidence_indices)} labels to eagle.\")\n",
    "\n",
    "# Retrain on fully updated dataset\n",
    "print(\"Retraining model with updated labels...\")\n",
    "model.fit(\n",
    "    [images_train, confidence_init],\n",
    "    preds,\n",
    "    batch_size=32,\n",
    "    epochs=3,  # Add more epochs for final retraining\n",
    "    validation_data=([images_val, np.ones((len(images_val), 1))], label_val),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Final counts\n",
    "print(f\"Final eagle count: {np.sum(label_train == 1)}\")\n",
    "print(f\"Final noneagle count: {np.sum(label_train == 0)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b988f3c-a1b6-4798-8f4a-bbc6878d2172",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### just to test distributions / debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38406e69-705d-44df-837e-d79871e2f2fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f0cea15-01b9-416e-9a34-e2a4e47b57cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly labeled eagles: 1040/1040\n",
      "Correctly labeled noneagles: 4160/4160\n"
     ]
    }
   ],
   "source": [
    "# Compare relabeled classes to original ground truth\n",
    "original_labels = new_labels  \n",
    "correct_eagles = np.sum((label_train == 1) & (original_labels == 1))  # True eagles as eagles\n",
    "correct_noneagles = np.sum((label_train == 0) & (original_labels == 0))  # True noneagles as noneagles\n",
    "\n",
    "print(f\"Correctly labeled eagles: {correct_eagles}/{np.sum(original_labels == 1)}\")\n",
    "print(f\"Correctly labeled noneagles: {correct_noneagles}/{np.sum(original_labels == 0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8b2ea307-66f6-4820-af0f-e7387923936e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean confidence for eagles: 0.0297\n",
      "Mean confidence for noneagles: 0.0079\n"
     ]
    }
   ],
   "source": [
    "eagle_confidence = preds[label_train == 1]\n",
    "noneagle_confidence = preds[label_train == 0]\n",
    "\n",
    "print(f\"Mean confidence for eagles: {eagle_confidence.mean():.4f}\")\n",
    "print(f\"Mean confidence for noneagles: {noneagle_confidence.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "091e90f8-5dd7-45d0-904b-b4f1e03d1997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: 285.7584, P-value: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "t_stat, p_val = ttest_ind(eagle_confidence, noneagle_confidence, equal_var=False)\n",
    "print(f\"T-statistic: {t_stat:.4f}, P-value: {p_val:.4e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "92a903ff-2813-4184-bbc5-479a20d2dbe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(eagle_confidence, bins=20, alpha=0.7, label='Eagles (1)')\n",
    "plt.hist(noneagle_confidence, bins=20, alpha=0.7, label='Noneagles (0)')\n",
    "plt.xlabel('Confidence Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Confidence Distribution')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8fe5eac0-43f7-49ec-a853-c79292cd062d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0: Label=0, Confidence=0.4747\n",
      "Sample 1: Label=1, Confidence=0.5125\n",
      "Sample 2: Label=1, Confidence=0.5125\n",
      "Sample 3: Label=1, Confidence=0.5125\n",
      "Sample 4: Label=1, Confidence=0.5125\n",
      "Sample 5: Label=1, Confidence=0.5125\n",
      "Sample 6: Label=1, Confidence=0.5125\n",
      "Sample 7: Label=0, Confidence=0.4747\n",
      "Sample 8: Label=1, Confidence=0.5125\n",
      "Sample 9: Label=1, Confidence=0.5125\n"
     ]
    }
   ],
   "source": [
    "# Get indices of ambiguous samples\n",
    "ambiguous_indices = np.where((preds > 0.4) & (preds < 0.6))[0]\n",
    "\n",
    "# Inspect some ambiguous samples (requires image visualization logic)\n",
    "for idx in ambiguous_indices[:10]:  # First 10 ambiguous cases\n",
    "    print(f\"Sample {idx}: Label={label_train[idx]}, Confidence={preds[idx]:.4f}\")\n",
    "    # Add your image visualization code here if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372577b8-e20f-4931-9411-7cdd8356c626",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
